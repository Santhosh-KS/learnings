{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "The key idea of DP, and of reinforcement learning generally, is the use of value functions to orgamize and stucture the search for good policies. In this chapter we see how DP can be used to compute the value functions. We can easily obtain optimal policies once we have found the optimal value functions, $v_*$ or $q_*$, which satisfy the Bellman optimality equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large v_*(s) = \\underset {a}{max} \\mathbb{E} \\big[R_{t+1} + \\gamma \\space v_*(S_{t+1}) \\space | \\space S_t = s,A_t=s\\big]$\n",
    "</p>\n",
    "$\\large = \\underset {a}{max} \\sum_{s',r}p(s',r \\space | \\space s,a)\\Big[r + \\gamma \\space v_*(s') \\Big] \\rightarrow (4.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large q_*(s,a) = \\mathbb{E} \\Big[ R_{t+1} + \\gamma \\underset {a}{max}q_*(S_{t+1},a') \\space | \\space S_t=2,A_t=a \\Big]$\n",
    "\n",
    "</p>\n",
    "$\\large = \\sum_{s',r}p(s',r \\space | \\space s,a) \\Big[r+\\gamma \\underset{a}{max}q_*(s',a')\\Big] \\rightarrow (4.2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all $s \\in S, a \\in A(s)$ and $s' \\in S^+$. DP algorithms are obtained by tuing Bellman equations such as 4.1 and 4.2 in to assignments, that is, into update rules for improving approximations of the desired value functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Evaluation (Prediction)\n",
    "\n",
    "First we consider how to compute the state-value function $v_\\pi$ for an arbitrary policy $\\pi$. This is called **policy evaluation** in the DP liteature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large v_\\pi(s) \\doteq \\mathbb{E}_\\pi[G_t \\space | \\space S_t=s]$\n",
    "</p>\n",
    "$\\large = \\mathbb{E}_\\pi[R_{t+1} + \\gamma G_{t+1} \\space | \\space S_t=s]$\n",
    "</p>\n",
    "$\\large = \\mathbb{E}_\\pi[R_{t+1} + \\gamma v_\\pi(S_{t+1}) \\space | \\space S_t=s] \\rightarrow (4.3)$\n",
    "</p>\n",
    "$\\large = \\sum_{a}\\pi(a|s)\\sum_{s',r}p(s',r|s,a)\\Big[ r + \\gamma v_\\pi(s')\\Big] \\rightarrow (4.4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\pi(a|s)$ is the probability of taking action $a$ in state $s$ under policy $\\pi$ and the expectations are subscripted by $\\pi$ to indicate that they are conditional on $\\pi$ being followed. The existence and uniqueness of $v_\\pi$ are guaranteed as lon as either $\\gamma < 1$ or eventual termination is guaranteed from all states under the policy $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the environment's dynamics are completely known, then 4.4 is a system of $|S|$ simultaneous linear equations in $|S|$ unknowns.\n",
    "\n",
    "Consider a sequence of approximate value functions $v_0,v_1,v_2,....$ each mapping $S^+$ to $\\mathbb{R}$ (the real numbers). The initial approximation, $v_0$, is chosen arbitrarily (except that the terminal state, if any, must give value 0) and each successive approximation is obtained by using the Bellman equation for $v_\\pi$ (4.4) as an update rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Large v_{k+1}(s) \\doteq \\mathbb{E}_\\pi[R_{t+1} + \\gamma v_k(S_{t+1} \\space | \\space S_t=s]$\n",
    "</p>\n",
    "$\\large = \\sum_a \\pi(a|s) \\sum_{s',r} p(s',r \\space | \\space s,a) \\Big[ r + \\gamma v_k(s') \\Big]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all $s \\in S$. Clearly, $v_k = v_\\pi$ is a fixed point for this update rule because the Bellman equation for $v_\\pi$ assures us of equality in this case. Indeed, the sequence $\\{v_k\\}$ can be shown in general to converge to $v_\\pi$ as $k \\rightarrow \\infty$ under the same conditions that guarantee the existence of $v_\\pi$. This algorith is called **iterative policy evaluation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.1**\n",
    "</p>\n",
    "The nonterminal states are $S = \\{1,2,....,14\\}$. There are four actions possible in each state, $A = \\{up, down, ight, left \\}$, which dtermininistically caus the corresponding state transitions, except that action that would take the agent off the grid in fact leave the state unchanged. Thus, for instance, $p(6,-1 \\space | \\space 5,right) = 1, \\space p(7,-1 \\space | \\space 7,right) =1$ and $p(10,r \\space | \\space 5, right) = 0$ for all $r \\in R$. This is an undiscounted, episodic task. The reward is $-1$ on all transitions untill the terminal state is reached. The terninal state is shaded in the figure. The expected reward function is thus $r(s,a,s') = -1$ for all states $s,s'$ and actions $a$. Suppose the agent follows the equiprobable random policy, compute by iterative policy evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawTable(mat):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_axis_off()\n",
    "    tb = Table(ax, bbox=[0, 0, 1, 1],)\n",
    "\n",
    "    nrows, ncols = mat.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "\n",
    "    # Add cells\n",
    "    for (i,j), val in np.ndenumerate(mat):\n",
    "        if (i == 0 and j == 0) or ( i == 3 and j == 3):\n",
    "            color = 'g'\n",
    "            val = 'Goal'\n",
    "        else:\n",
    "            color = 'w'\n",
    "\n",
    "        tb.add_cell(i, j, width, height, text=val,loc='center', facecolor=color)\n",
    "\n",
    "    ax.add_table(tb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = np.array(range(16)).reshape(4,4)\n",
    "DrawTable(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, the cells with green color are the terminal state for each episodic tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORLD_SIZE = 4\n",
    "\n",
    "# left, up, right, down\n",
    "Actions =[np.array([-1,0]),\n",
    "         np.array([0,-1]),\n",
    "         np.array([1,0]),\n",
    "         np.array([0,1])]\n",
    "\n",
    "Prob = 1/len(Actions)\n",
    "Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Step(state, action):\n",
    "    state = np.array(state)\n",
    "    next_state = (state + action).tolist()\n",
    "    x, y = next_state\n",
    "    if x < 0 or x >= WORLD_SIZE or y < 0 or y >= WORLD_SIZE:\n",
    "        next_state = state\n",
    "    \n",
    "    reward = -1\n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsTerminalStateReached(state):\n",
    "    x,y=state\n",
    "    return (x == 0 and y == 0) or (x == WORLD_SIZE-1 and y == WORLD_SIZE-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value got converged on 16 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NewStateValues = np.zeros((WORLD_SIZE,WORLD_SIZE))\n",
    "StateValues = NewStateValues.copy()\n",
    "count = 0\n",
    "while True:\n",
    "    count +=1\n",
    "    for i in range(WORLD_SIZE):\n",
    "        for j in range(WORLD_SIZE):\n",
    "            if IsTerminalStateReached([i,j]):\n",
    "                continue\n",
    "            value = 0\n",
    "            for act in Actions:\n",
    "                (next_x,next_y),reward = Step([i,j],act)\n",
    "                value += Prob * (reward + NewStateValues[next_x,next_y])\n",
    "            NewStateValues[i,j] = round(value) \n",
    "            #print(f'{i},{j} = {value}')\n",
    "    #print(f'abs sum = {np.sum(np.abs(NewStateValues - StateValues))}')\n",
    "    if np.sum(np.abs(NewStateValues - StateValues)) < 1e-4:\n",
    "        StateValues = NewStateValues.copy()\n",
    "        break\n",
    "    StateValues = NewStateValues.copy()\n",
    "\n",
    "print(f'Value got converged on {count} iterations')\n",
    "#print(StateValues)\n",
    "DrawTable(StateValues)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Policy Evaluation, for estimating $V \\approx v_\\pi$\n",
    "\n",
    "**Algorighm**\n",
    ">\n",
    "Input $\\pi$, the policy to be evaluated\n",
    "Alogirhm parameter: a small threshold $\\theta > 0$ determining accuracy of estimation\n",
    "Initialize $\\large V(s)$ for all $s \\in \\mathbf{S}^+$, arbitrarily except that $V(terminal) = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large\n",
    "\\begin{align}\n",
    " Loop: {} \\\\\n",
    "     & \\Delta \\leftarrow 0 \\\\\n",
    "     & \\text{Loop for each} \\space s \\in S: \\\\\n",
    "         &&& v \\leftarrow V(s) \\\\\n",
    "         &&& V(s) \\leftarrow \\sum_a \\pi(a|s) \\space \\sum_{s',r'}p(s',r|s,a)\\Big[r +\\gamma V(s') \\Big] \\\\\n",
    "         &&& \\Delta \\leftarrow max(\\Delta,|v-V(s)|) \\\\\n",
    "\\end{align}\n",
    "$\n",
    ">\n",
    "$\\large \\text{until} \\Delta < \\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is work in progress to implement the above logic. Not correct\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "States = np.array(range(16))\n",
    "Rewards = -1\n",
    "V_s = np.zeros(16)\n",
    "#theta = np.random.random_sample()\n",
    "theta = 1e-4\n",
    "prob = 1/len(States)\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = 0.0001\n",
      "number of iterations 15736\n",
      "[-0.06622517 -0.06622517 -0.06622517 -0.06622517 -0.06622517 -0.06622517\n",
      " -0.06622517 -0.06622517 -0.06622517 -0.06622517 -0.06622517 -0.06622517\n",
      " -0.06622517 -0.06622517 -0.06622517 -0.06622517]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "while True:\n",
    "    delta = np.random.random_sample();\n",
    "    count +=1\n",
    "    for i,s in enumerate(States):\n",
    "        v = V_s\n",
    "        if i == States[0]:\n",
    "            i_dash = np.random.randint(0,10)\n",
    "        V_s[i] = prob * (Rewards + gamma * V_s[i_dash] )\n",
    "        delta = max(delta, np.abs(v.sum()-V_s.sum()))\n",
    "    if delta < theta:\n",
    "        break\n",
    "print(f'theta = {theta}')\n",
    "print(f'number of iterations {count}')\n",
    "print(V_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_django",
   "language": "python",
   "name": "py37_django"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
